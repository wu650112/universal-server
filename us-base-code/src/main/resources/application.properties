## 指定kafka server的地址，集群配多个，中间，逗号隔开
#spring.kafka.bootstrap-servers=10.255.245.15:9092
##重试次数
#spring.kafka.producer.retries=2
##批量发送的消息数量
#spring.kafka.producer.batch-size=1000
##32MB的批处理缓冲区
#spring.kafka.producer.buffer-memory=33554432
##  1.默认消费者组 在Kafka中，group.id 是消费者组的标识，
### 2.但并不是强制设置的。如果你不指定 group.id，
### 3.那么消费者将被视为一个独立的消费者，而不会加入到任何消费者组中。
### 4.这种情况下，每个消费者实例都会独立地消费主题的消息，而不会协同工作。
##spring.kafka.consumer.group-id=crm-user-service
##最早未被消费的offset
#spring.kafka.consumer.auto-offset-reset=earliest
## 批量一次最大拉取数据量
#spring.kafka.consumer.max-poll-records=4000
##是否自动提交
#spring.kafka.consumer.enable-auto-commit=true
##自动提交时间间隔，单位ms
#spring.kafka.consumer.auto-commit-interval=1000

# token 过期时间
#us.web.token.active.time=3600000

# MyBatis Plus 配置
mybatis-plus.mapper-locations=classpath:mapper/**/*.xml
mybatis-plus.type-aliases-package=com.us.bizs.entity
#主键类型  0:"数据库ID自增", 1:"用户输入ID",2:"全局唯一ID (数字类型唯一ID)", 3:"全局唯一ID UUID";
#mybatis-plus.global-config.id-type=2
#字段策略 0:"忽略判断",1:"非 NULL 判断"),2:"非空判断"
#mybatis-plus.global-config.field-strategy=2
#驼峰下划线转换
mybatis-plus.global-config.db-column-underline=true
#刷新mapper 调试神器
#mybatis-plus.global-config.refresh-mapper=true
#数据库大写下划线转换
mybatis-plus.global-config.capital-mode=true
#序列接口实现类配置
#mybatis-plus.global-config.key-generator=com.baomidou.springboot.xxx
#逻辑删除配置
#mybatis-plus.global-config.logic-delete-value=0
#mybatis-plus.global-config.logic-not-delete-value=1
#自定义填充策略接口实现
#mybatis-plus.global-config.meta-object-handler=com.baomidou.springboot.xxx
#自定义SQL注入器
#mybatis-plus.global-config.sql-injector=com.baomidou.springboot.xxx
mybatis-plus.configuration.cache-enabled=false
#mybatis日志打印
mybatis-plus.configuration.log-impl=org.apache.ibatis.logging.stdout.StdOutImpl
mybatis-plus.configuration.map-underscore-to-camel-case=true

logging.config=classpath:logback-spring.xml
log.path=C:/Users/admin/Desktop/us-log


